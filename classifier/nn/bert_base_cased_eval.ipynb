{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModel, pipeline, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from datasets import Dataset, load_metric\n",
    "import pandas as pd\n",
    "from transformers import TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding=True, truncation=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained('../../../Files/models/bert_base_cased_model/fully_trained/checkpoint-3237/')\n",
    "\n",
    "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('../../../Files/Comments/train/test_split_comments.pickle')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = []\n",
    "for i,j in test.iterrows():\n",
    "    testlist.append(j['cleanBody'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classifier(testlist[:100], top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 2, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 2, 2, 1, 0, 2, 0, 2,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0:100]['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_1', 'score': 0.9958221912384033},\n",
       "  {'label': 'LABEL_2', 'score': 0.00371171603910625},\n",
       "  {'label': 'LABEL_0', 'score': 0.00046611326979473233}],\n",
       " [{'label': 'LABEL_1', 'score': 0.8922913670539856},\n",
       "  {'label': 'LABEL_0', 'score': 0.06190100684762001},\n",
       "  {'label': 'LABEL_2', 'score': 0.04580756649374962}],\n",
       " [{'label': 'LABEL_2', 'score': 0.39818114042282104},\n",
       "  {'label': 'LABEL_1', 'score': 0.33800938725471497},\n",
       "  {'label': 'LABEL_0', 'score': 0.26380953192710876}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9936386942863464},\n",
       "  {'label': 'LABEL_2', 'score': 0.005611531436443329},\n",
       "  {'label': 'LABEL_0', 'score': 0.0007498113554902375}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9423483610153198},\n",
       "  {'label': 'LABEL_2', 'score': 0.05142098665237427},\n",
       "  {'label': 'LABEL_0', 'score': 0.006230669096112251}],\n",
       " [{'label': 'LABEL_1', 'score': 0.983226478099823},\n",
       "  {'label': 'LABEL_2', 'score': 0.011175542138516903},\n",
       "  {'label': 'LABEL_0', 'score': 0.005597958341240883}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9529594779014587},\n",
       "  {'label': 'LABEL_2', 'score': 0.04577184468507767},\n",
       "  {'label': 'LABEL_0', 'score': 0.0012686473783105612}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9953153133392334},\n",
       "  {'label': 'LABEL_1', 'score': 0.003425627714022994},\n",
       "  {'label': 'LABEL_2', 'score': 0.0012589890975505114}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9985502362251282},\n",
       "  {'label': 'LABEL_1', 'score': 0.0010118635836988688},\n",
       "  {'label': 'LABEL_2', 'score': 0.0004379305464681238}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9927995204925537},\n",
       "  {'label': 'LABEL_2', 'score': 0.00691076647490263},\n",
       "  {'label': 'LABEL_0', 'score': 0.00028969295090064406}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9992045760154724},\n",
       "  {'label': 'LABEL_2', 'score': 0.0004543805553112179},\n",
       "  {'label': 'LABEL_1', 'score': 0.00034098190371878445}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9990435242652893},\n",
       "  {'label': 'LABEL_1', 'score': 0.0005645201308652759},\n",
       "  {'label': 'LABEL_2', 'score': 0.0003918902948498726}],\n",
       " [{'label': 'LABEL_0', 'score': 0.98853999376297},\n",
       "  {'label': 'LABEL_1', 'score': 0.00965113379061222},\n",
       "  {'label': 'LABEL_2', 'score': 0.0018089457880705595}],\n",
       " [{'label': 'LABEL_2', 'score': 0.512831449508667},\n",
       "  {'label': 'LABEL_1', 'score': 0.4869787395000458},\n",
       "  {'label': 'LABEL_0', 'score': 0.00018983134941663593}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9153744578361511},\n",
       "  {'label': 'LABEL_1', 'score': 0.05708002299070358},\n",
       "  {'label': 'LABEL_2', 'score': 0.027545448392629623}],\n",
       " [{'label': 'LABEL_0', 'score': 0.6350510716438293},\n",
       "  {'label': 'LABEL_1', 'score': 0.35202500224113464},\n",
       "  {'label': 'LABEL_2', 'score': 0.012923875823616982}],\n",
       " [{'label': 'LABEL_2', 'score': 0.9983181953430176},\n",
       "  {'label': 'LABEL_1', 'score': 0.0015800296096131206},\n",
       "  {'label': 'LABEL_0', 'score': 0.00010175062925554812}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9905063509941101},\n",
       "  {'label': 'LABEL_1', 'score': 0.008169414475560188},\n",
       "  {'label': 'LABEL_2', 'score': 0.0013242202112451196}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9520002007484436},\n",
       "  {'label': 'LABEL_2', 'score': 0.03886270523071289},\n",
       "  {'label': 'LABEL_1', 'score': 0.009137066081166267}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9126043319702148},\n",
       "  {'label': 'LABEL_0', 'score': 0.08442061394453049},\n",
       "  {'label': 'LABEL_2', 'score': 0.002974958624690771}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9761782288551331},\n",
       "  {'label': 'LABEL_2', 'score': 0.021601302549242973},\n",
       "  {'label': 'LABEL_0', 'score': 0.0022204008419066668}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9989197254180908},\n",
       "  {'label': 'LABEL_1', 'score': 0.000654113944619894},\n",
       "  {'label': 'LABEL_2', 'score': 0.00042620731983333826}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9970406889915466},\n",
       "  {'label': 'LABEL_2', 'score': 0.0024498607963323593},\n",
       "  {'label': 'LABEL_0', 'score': 0.0005094600492157042}],\n",
       " [{'label': 'LABEL_1', 'score': 0.959395706653595},\n",
       "  {'label': 'LABEL_2', 'score': 0.02839832380414009},\n",
       "  {'label': 'LABEL_0', 'score': 0.012205866165459156}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9153744578361511},\n",
       "  {'label': 'LABEL_1', 'score': 0.05708002299070358},\n",
       "  {'label': 'LABEL_2', 'score': 0.027545448392629623}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9961330890655518},\n",
       "  {'label': 'LABEL_2', 'score': 0.0034252116456627846},\n",
       "  {'label': 'LABEL_0', 'score': 0.00044175234506838024}],\n",
       " [{'label': 'LABEL_1', 'score': 0.6766064167022705},\n",
       "  {'label': 'LABEL_0', 'score': 0.31044745445251465},\n",
       "  {'label': 'LABEL_2', 'score': 0.012946157716214657}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9274386167526245},\n",
       "  {'label': 'LABEL_1', 'score': 0.061433013528585434},\n",
       "  {'label': 'LABEL_2', 'score': 0.011128345504403114}],\n",
       " [{'label': 'LABEL_0', 'score': 0.998415470123291},\n",
       "  {'label': 'LABEL_1', 'score': 0.0009671769803389907},\n",
       "  {'label': 'LABEL_2', 'score': 0.0006173511501401663}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9958363771438599},\n",
       "  {'label': 'LABEL_2', 'score': 0.0033044356387108564},\n",
       "  {'label': 'LABEL_0', 'score': 0.000859172607306391}],\n",
       " [{'label': 'LABEL_1', 'score': 0.7136465311050415},\n",
       "  {'label': 'LABEL_0', 'score': 0.24093808233737946},\n",
       "  {'label': 'LABEL_2', 'score': 0.045415375381708145}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9991357922554016},\n",
       "  {'label': 'LABEL_2', 'score': 0.0004981135134585202},\n",
       "  {'label': 'LABEL_1', 'score': 0.0003661290102172643}],\n",
       " [{'label': 'LABEL_2', 'score': 0.9787493348121643},\n",
       "  {'label': 'LABEL_1', 'score': 0.021172838285565376},\n",
       "  {'label': 'LABEL_0', 'score': 7.78586691012606e-05}],\n",
       " [{'label': 'LABEL_2', 'score': 0.7430230379104614},\n",
       "  {'label': 'LABEL_1', 'score': 0.19760143756866455},\n",
       "  {'label': 'LABEL_0', 'score': 0.0593755804002285}],\n",
       " [{'label': 'LABEL_1', 'score': 0.8792884349822998},\n",
       "  {'label': 'LABEL_2', 'score': 0.06117543205618858},\n",
       "  {'label': 'LABEL_0', 'score': 0.05953618139028549}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9984279870986938},\n",
       "  {'label': 'LABEL_1', 'score': 0.0011243503540754318},\n",
       "  {'label': 'LABEL_2', 'score': 0.00044768815860152245}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9364084601402283},\n",
       "  {'label': 'LABEL_2', 'score': 0.06303524971008301},\n",
       "  {'label': 'LABEL_0', 'score': 0.000556347775273025}],\n",
       " [{'label': 'LABEL_0', 'score': 0.8551830649375916},\n",
       "  {'label': 'LABEL_1', 'score': 0.13107922673225403},\n",
       "  {'label': 'LABEL_2', 'score': 0.013737672939896584}],\n",
       " [{'label': 'LABEL_1', 'score': 0.7262214422225952},\n",
       "  {'label': 'LABEL_0', 'score': 0.22782795131206512},\n",
       "  {'label': 'LABEL_2', 'score': 0.045950569212436676}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9981153011322021},\n",
       "  {'label': 'LABEL_2', 'score': 0.0014971890486776829},\n",
       "  {'label': 'LABEL_0', 'score': 0.0003875168622471392}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9657170176506042},\n",
       "  {'label': 'LABEL_0', 'score': 0.03183474764227867},\n",
       "  {'label': 'LABEL_2', 'score': 0.002448329934850335}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9153744578361511},\n",
       "  {'label': 'LABEL_1', 'score': 0.05708002299070358},\n",
       "  {'label': 'LABEL_2', 'score': 0.027545448392629623}],\n",
       " [{'label': 'LABEL_1', 'score': 0.4977323114871979},\n",
       "  {'label': 'LABEL_0', 'score': 0.40810906887054443},\n",
       "  {'label': 'LABEL_2', 'score': 0.09415866434574127}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9933140873908997},\n",
       "  {'label': 'LABEL_2', 'score': 0.0063807182013988495},\n",
       "  {'label': 'LABEL_0', 'score': 0.00030510034412145615}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9910832643508911},\n",
       "  {'label': 'LABEL_1', 'score': 0.005171080585569143},\n",
       "  {'label': 'LABEL_2', 'score': 0.003745768219232559}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9920918941497803},\n",
       "  {'label': 'LABEL_2', 'score': 0.006762092001736164},\n",
       "  {'label': 'LABEL_0', 'score': 0.001146055874414742}],\n",
       " [{'label': 'LABEL_1', 'score': 0.7495509386062622},\n",
       "  {'label': 'LABEL_0', 'score': 0.19499626755714417},\n",
       "  {'label': 'LABEL_2', 'score': 0.055452827364206314}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9990805387496948},\n",
       "  {'label': 'LABEL_2', 'score': 0.0005465398426167667},\n",
       "  {'label': 'LABEL_1', 'score': 0.00037285496364347637}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9025458097457886},\n",
       "  {'label': 'LABEL_0', 'score': 0.079717718064785},\n",
       "  {'label': 'LABEL_2', 'score': 0.017736513167619705}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9931584000587463},\n",
       "  {'label': 'LABEL_2', 'score': 0.006171831861138344},\n",
       "  {'label': 'LABEL_0', 'score': 0.0006697945646010339}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9964894652366638},\n",
       "  {'label': 'LABEL_2', 'score': 0.0022084347438067198},\n",
       "  {'label': 'LABEL_1', 'score': 0.0013021217891946435}],\n",
       " [{'label': 'LABEL_1', 'score': 0.8694433569908142},\n",
       "  {'label': 'LABEL_2', 'score': 0.12160232663154602},\n",
       "  {'label': 'LABEL_0', 'score': 0.008954279124736786}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9678787589073181},\n",
       "  {'label': 'LABEL_1', 'score': 0.029063886031508446},\n",
       "  {'label': 'LABEL_2', 'score': 0.003057328052818775}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9846718907356262},\n",
       "  {'label': 'LABEL_2', 'score': 0.013596546836197376},\n",
       "  {'label': 'LABEL_0', 'score': 0.0017314654542133212}],\n",
       " [{'label': 'LABEL_1', 'score': 0.640346109867096},\n",
       "  {'label': 'LABEL_2', 'score': 0.3593812584877014},\n",
       "  {'label': 'LABEL_0', 'score': 0.0002726711391005665}],\n",
       " [{'label': 'LABEL_1', 'score': 0.8564664721488953},\n",
       "  {'label': 'LABEL_2', 'score': 0.1047697514295578},\n",
       "  {'label': 'LABEL_0', 'score': 0.038763705641031265}],\n",
       " [{'label': 'LABEL_0', 'score': 0.5315024256706238},\n",
       "  {'label': 'LABEL_1', 'score': 0.3491703271865845},\n",
       "  {'label': 'LABEL_2', 'score': 0.11932729184627533}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9662985801696777},\n",
       "  {'label': 'LABEL_1', 'score': 0.018777159973978996},\n",
       "  {'label': 'LABEL_2', 'score': 0.01492422167211771}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9911230802536011},\n",
       "  {'label': 'LABEL_2', 'score': 0.008629177697002888},\n",
       "  {'label': 'LABEL_0', 'score': 0.000247787480475381}],\n",
       " [{'label': 'LABEL_1', 'score': 0.8834840059280396},\n",
       "  {'label': 'LABEL_2', 'score': 0.09123293310403824},\n",
       "  {'label': 'LABEL_0', 'score': 0.025283096358180046}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9898534417152405},\n",
       "  {'label': 'LABEL_0', 'score': 0.005945523735135794},\n",
       "  {'label': 'LABEL_2', 'score': 0.004201005678623915}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9989064931869507},\n",
       "  {'label': 'LABEL_1', 'score': 0.0005932307685725391},\n",
       "  {'label': 'LABEL_2', 'score': 0.0005002598045393825}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9992194175720215},\n",
       "  {'label': 'LABEL_1', 'score': 0.0003914128174073994},\n",
       "  {'label': 'LABEL_2', 'score': 0.00038916501216590405}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9990054965019226},\n",
       "  {'label': 'LABEL_1', 'score': 0.0005853979964740574},\n",
       "  {'label': 'LABEL_2', 'score': 0.0004090965667273849}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9153744578361511},\n",
       "  {'label': 'LABEL_1', 'score': 0.05708002299070358},\n",
       "  {'label': 'LABEL_2', 'score': 0.027545448392629623}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9777324199676514},\n",
       "  {'label': 'LABEL_1', 'score': 0.01906852424144745},\n",
       "  {'label': 'LABEL_2', 'score': 0.00319913262501359}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9992645382881165},\n",
       "  {'label': 'LABEL_1', 'score': 0.00037562273791991174},\n",
       "  {'label': 'LABEL_2', 'score': 0.000359828001819551}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9970554113388062},\n",
       "  {'label': 'LABEL_2', 'score': 0.002412384143099189},\n",
       "  {'label': 'LABEL_0', 'score': 0.0005322431097738445}],\n",
       " [{'label': 'LABEL_1', 'score': 0.7466990947723389},\n",
       "  {'label': 'LABEL_2', 'score': 0.2527864873409271},\n",
       "  {'label': 'LABEL_0', 'score': 0.0005143680609762669}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9986718893051147},\n",
       "  {'label': 'LABEL_2', 'score': 0.0009349253377877176},\n",
       "  {'label': 'LABEL_1', 'score': 0.0003931806131731719}],\n",
       " [{'label': 'LABEL_2', 'score': 0.8276338577270508},\n",
       "  {'label': 'LABEL_1', 'score': 0.17205607891082764},\n",
       "  {'label': 'LABEL_0', 'score': 0.00031006932840682566}],\n",
       " [{'label': 'LABEL_1', 'score': 0.997614860534668},\n",
       "  {'label': 'LABEL_2', 'score': 0.0016369970981031656},\n",
       "  {'label': 'LABEL_0', 'score': 0.0007481182692572474}],\n",
       " [{'label': 'LABEL_2', 'score': 0.8118093013763428},\n",
       "  {'label': 'LABEL_1', 'score': 0.1872948408126831},\n",
       "  {'label': 'LABEL_0', 'score': 0.0008959065889939666}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9846603274345398},\n",
       "  {'label': 'LABEL_2', 'score': 0.009372416883707047},\n",
       "  {'label': 'LABEL_0', 'score': 0.005967312958091497}],\n",
       " [{'label': 'LABEL_1', 'score': 0.861718475818634},\n",
       "  {'label': 'LABEL_0', 'score': 0.09355095028877258},\n",
       "  {'label': 'LABEL_2', 'score': 0.044730592519044876}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9153744578361511},\n",
       "  {'label': 'LABEL_1', 'score': 0.05708002299070358},\n",
       "  {'label': 'LABEL_2', 'score': 0.027545448392629623}],\n",
       " [{'label': 'LABEL_1', 'score': 0.5067548155784607},\n",
       "  {'label': 'LABEL_0', 'score': 0.43080756068229675},\n",
       "  {'label': 'LABEL_2', 'score': 0.06243766471743584}],\n",
       " [{'label': 'LABEL_0', 'score': 0.7626743316650391},\n",
       "  {'label': 'LABEL_1', 'score': 0.20982292294502258},\n",
       "  {'label': 'LABEL_2', 'score': 0.027502791956067085}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9557939767837524},\n",
       "  {'label': 'LABEL_1', 'score': 0.04241921380162239},\n",
       "  {'label': 'LABEL_2', 'score': 0.0017867705319076777}],\n",
       " [{'label': 'LABEL_0', 'score': 0.5315024256706238},\n",
       "  {'label': 'LABEL_1', 'score': 0.3491703271865845},\n",
       "  {'label': 'LABEL_2', 'score': 0.11932729184627533}],\n",
       " [{'label': 'LABEL_1', 'score': 0.6381253600120544},\n",
       "  {'label': 'LABEL_0', 'score': 0.3203083574771881},\n",
       "  {'label': 'LABEL_2', 'score': 0.04156629741191864}],\n",
       " [{'label': 'LABEL_2', 'score': 0.9749665260314941},\n",
       "  {'label': 'LABEL_1', 'score': 0.024841463193297386},\n",
       "  {'label': 'LABEL_0', 'score': 0.00019203583360649645}],\n",
       " [{'label': 'LABEL_1', 'score': 0.7538700699806213},\n",
       "  {'label': 'LABEL_2', 'score': 0.14579319953918457},\n",
       "  {'label': 'LABEL_0', 'score': 0.10033676028251648}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9879289865493774},\n",
       "  {'label': 'LABEL_2', 'score': 0.011330165900290012},\n",
       "  {'label': 'LABEL_0', 'score': 0.0007407930097542703}],\n",
       " [{'label': 'LABEL_1', 'score': 0.5123453140258789},\n",
       "  {'label': 'LABEL_0', 'score': 0.4437800943851471},\n",
       "  {'label': 'LABEL_2', 'score': 0.04387462139129639}],\n",
       " [{'label': 'LABEL_2', 'score': 0.711659848690033},\n",
       "  {'label': 'LABEL_1', 'score': 0.28690987825393677},\n",
       "  {'label': 'LABEL_0', 'score': 0.0014302741037681699}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9895517230033875},\n",
       "  {'label': 'LABEL_2', 'score': 0.00994199886918068},\n",
       "  {'label': 'LABEL_0', 'score': 0.0005063356948085129}],\n",
       " [{'label': 'LABEL_2', 'score': 0.9827575087547302},\n",
       "  {'label': 'LABEL_1', 'score': 0.017179492861032486},\n",
       "  {'label': 'LABEL_0', 'score': 6.297305662883446e-05}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9369446635246277},\n",
       "  {'label': 'LABEL_2', 'score': 0.042250167578458786},\n",
       "  {'label': 'LABEL_1', 'score': 0.02080518566071987}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9761221408843994},\n",
       "  {'label': 'LABEL_0', 'score': 0.01718042977154255},\n",
       "  {'label': 'LABEL_2', 'score': 0.006697441451251507}],\n",
       " [{'label': 'LABEL_0', 'score': 0.5315024256706238},\n",
       "  {'label': 'LABEL_1', 'score': 0.3491703271865845},\n",
       "  {'label': 'LABEL_2', 'score': 0.11932729184627533}],\n",
       " [{'label': 'LABEL_1', 'score': 0.986453115940094},\n",
       "  {'label': 'LABEL_2', 'score': 0.008307024836540222},\n",
       "  {'label': 'LABEL_0', 'score': 0.005239871796220541}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9971535205841064},\n",
       "  {'label': 'LABEL_2', 'score': 0.0023708653170615435},\n",
       "  {'label': 'LABEL_0', 'score': 0.0004755773697979748}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9953525066375732},\n",
       "  {'label': 'LABEL_1', 'score': 0.0028355910908430815},\n",
       "  {'label': 'LABEL_2', 'score': 0.0018118651350960135}],\n",
       " [{'label': 'LABEL_1', 'score': 0.5261558294296265},\n",
       "  {'label': 'LABEL_0', 'score': 0.3325209617614746},\n",
       "  {'label': 'LABEL_2', 'score': 0.1413232535123825}],\n",
       " [{'label': 'LABEL_1', 'score': 0.7344690561294556},\n",
       "  {'label': 'LABEL_2', 'score': 0.2652091383934021},\n",
       "  {'label': 'LABEL_0', 'score': 0.0003218152851331979}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9904060959815979},\n",
       "  {'label': 'LABEL_2', 'score': 0.008816072717308998},\n",
       "  {'label': 'LABEL_0', 'score': 0.0007778546423651278}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9959807395935059},\n",
       "  {'label': 'LABEL_1', 'score': 0.0028572971932590008},\n",
       "  {'label': 'LABEL_2', 'score': 0.0011620486620813608}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9983885288238525},\n",
       "  {'label': 'LABEL_1', 'score': 0.0010017900494858623},\n",
       "  {'label': 'LABEL_2', 'score': 0.0006096937577240169}],\n",
       " [{'label': 'LABEL_1', 'score': 0.9951128363609314},\n",
       "  {'label': 'LABEL_2', 'score': 0.0032275032717734575},\n",
       "  {'label': 'LABEL_0', 'score': 0.001659731613472104}]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding=\"max_length\", truncation=True)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('../../../Files/models/bert_base_cased_model/fully_trained/checkpoint-3237/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classifier(testlist[:100], top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9958221912384033},\n",
       " {'label': 'LABEL_2', 'score': 0.00371171603910625},\n",
       " {'label': 'LABEL_0', 'score': 0.00046611326979473233}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fh/yf9jwszj6d5_1_xhfz_l6k000000gn/T/ipykernel_51638/4264278197.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test2.at[i, 'pred_1'] = np.int64(results[i][0]['label'][-1])\n",
      "/var/folders/fh/yf9jwszj6d5_1_xhfz_l6k000000gn/T/ipykernel_51638/4264278197.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test2.at[i, 'conf_1'] = results[i][0]['score']\n",
      "/var/folders/fh/yf9jwszj6d5_1_xhfz_l6k000000gn/T/ipykernel_51638/4264278197.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test2.at[i, 'pred_2'] = np.int64(results[i][1]['label'][-1])\n",
      "/var/folders/fh/yf9jwszj6d5_1_xhfz_l6k000000gn/T/ipykernel_51638/4264278197.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test2.at[i, 'conf_2'] = results[i][1]['score']\n"
     ]
    }
   ],
   "source": [
    "for i, j in test2.iterrows():\n",
    "    test2.at[i, 'pred_1'] = np.int64(results[i][0]['label'][-1])\n",
    "    test2.at[i, 'conf_1'] = results[i][0]['score']\n",
    "    test2.at[i, 'pred_2'] = np.int64(results[i][1]['label'][-1])\n",
    "    test2.at[i, 'conf_2'] = results[i][1]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.loc[ test['label'] == 1, 'label'] = 4\n",
    "test2.loc[ test['label'] == 0, 'label'] = 1\n",
    "test.loc[ test['label'] == 4, 'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xbg\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(y_test, y_pred, model ):\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    y_pred_onehot = pd.get_dummies(y_pred)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_pred_onehot, multi_class='ovo')\n",
    "    print('Model performance for {model}'.format(model=model))\n",
    "    print('------------------------------------------------')\n",
    "    print('Accuracy is ', acc)\n",
    "    print('F1 is ', f1)\n",
    "    print('ROC AUC Score is ', roc_auc)\n",
    "    print('------------------------------------------------')\n",
    "\n",
    "    metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "    plt.show()\n",
    "    df = pd.DataFrame(metrics.confusion_matrix(y_test, y_pred))\n",
    "    df2 = df.div(df.sum(axis=1), axis=0)\n",
    "    ax = sns.heatmap(df2)\n",
    "    ax.set(xlabel='Predicted', ylabel='Actual', title=f'Confusion Matrix for {model}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for BERT\n",
      "------------------------------------------------\n",
      "Accuracy is  0.7\n",
      "F1 is  0.6606848628125224\n",
      "ROC AUC Score is  0.7680436117936118\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(test2['label'], test2['pred_1'], 'BERT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLOW WAY, don't look here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3500/1408474 [04:49<32:17:12, 12.09it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jakobschlierf/Desktop/Master/Thesis/Github/classifier/nn/bert_base_cased_eval.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jakobschlierf/Desktop/Master/Thesis/Github/classifier/nn/bert_base_cased_eval.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predictions \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jakobschlierf/Desktop/Master/Thesis/Github/classifier/nn/bert_base_cased_eval.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(test))):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jakobschlierf/Desktop/Master/Thesis/Github/classifier/nn/bert_base_cased_eval.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     predictions\u001b[39m.\u001b[39mappend(classifier(test[i]))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:138\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    105\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    139\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    140\u001b[0m         \u001b[39m# This pipeline is odd, and return a list when single item is run\u001b[39;00m\n\u001b[1;32m    141\u001b[0m         \u001b[39mreturn\u001b[39;00m [result]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/pipelines/base.py:1032\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[39mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1029\u001b[0m     final_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[1;32m   1030\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1031\u001b[0m     )\n\u001b[0;32m-> 1032\u001b[0m     outputs \u001b[39m=\u001b[39m [output \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_iterator]\n\u001b[1;32m   1033\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n\u001b[1;32m   1034\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/pipelines/base.py:1032\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[39mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1029\u001b[0m     final_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[1;32m   1030\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1031\u001b[0m     )\n\u001b[0;32m-> 1032\u001b[0m     outputs \u001b[39m=\u001b[39m [output \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_iterator]\n\u001b[1;32m   1033\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n\u001b[1;32m   1034\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:111\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[1;32m    110\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    112\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    113\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:112\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    111\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator)\n\u001b[0;32m--> 112\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(item, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m    113\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[39m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/pipelines/base.py:959\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m    958\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 959\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m    960\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    961\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:163\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward\u001b[39m(\u001b[39mself\u001b[39m, model_inputs):\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1556\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1548\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1549\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1550\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1551\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1554\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1556\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1557\u001b[0m     input_ids,\n\u001b[1;32m   1558\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1559\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1560\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1561\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1562\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1563\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1564\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1565\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1566\u001b[0m )\n\u001b[1;32m   1568\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1570\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1018\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1009\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1011\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1012\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1013\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1017\u001b[0m )\n\u001b[0;32m-> 1018\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1019\u001b[0m     embedding_output,\n\u001b[1;32m   1020\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1021\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1022\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1023\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1024\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1025\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1026\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1027\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1028\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1029\u001b[0m )\n\u001b[1;32m   1030\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1031\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    598\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    599\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    600\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    608\u001b[0m         hidden_states,\n\u001b[1;32m    609\u001b[0m         attention_mask,\n\u001b[1;32m    610\u001b[0m         layer_head_mask,\n\u001b[1;32m    611\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    612\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    613\u001b[0m         past_key_value,\n\u001b[1;32m    614\u001b[0m         output_attentions,\n\u001b[1;32m    615\u001b[0m     )\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:535\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    532\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    533\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 535\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    536\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    537\u001b[0m )\n\u001b[1;32m    538\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    540\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/pytorch_utils.py:241\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 241\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:548\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m    547\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 548\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[1;32m    549\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:460\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 460\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    461\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    462\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reddit_env_test/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "predictions = []\n",
    "for i in tqdm(range(len(test))):\n",
    "    predictions.append(classifier(test[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('reddit_env_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c5bfe69c2b2d435baea75ee1a7865fc7666bb526179204de658e4f2811cb086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
