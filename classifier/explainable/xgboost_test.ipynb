{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import spacy\n",
    "import numpy as np\n",
    "import sklearn as skl \n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'label'\n",
    "input_column = 'cleanTitle'\n",
    "\n",
    "train_data = pd.read_pickle('../../../Files/Submissions/train/sets/train_split_submission.pickle') \n",
    "valid_data = pd.read_pickle('../../../Files/Submissions/train/sets/val_split_submission.pickle')\n",
    "test_data = pd.read_pickle('../../../Files/Submissions/train/sets/test_split_submission.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'label'\n",
    "input_column = 'cleanText'\n",
    "\n",
    "train_data = pd.read_csv('../../../Files/Submissions/train/train2.csv', sep='|') \n",
    "# valid_data = pd.read_pi('../../../Files/Submissions/train/sets/val_split_submission.pickle')\n",
    "test_data = pd.read_csv('../../../Files/Submissions/train/test2.csv', sep='|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = train_data[[target, input_column]]\n",
    "# valid_data = valid_data[[target, input_column]]\n",
    "test_data = test_data[[target, input_column]]\n",
    "\n",
    "data = pd.concat([train_data, valid_data, test_data])\n",
    "\n",
    "\n",
    "train_instances = train_data[input_column].apply(str).apply(str.split)\n",
    "train_labels = train_data[target]\n",
    "\n",
    "# collect known word tokens and tags\n",
    "wordset, labelset = set(), set()\n",
    "\n",
    "# collect tags from all data, to prevent unseen labels\n",
    "labelset.update(set(data[target]))\n",
    "\n",
    "# get the vocabulary\n",
    "for words in train_instances:\n",
    "    wordset.update(set(words))\n",
    "\n",
    "# map words and tags into ints\n",
    "PAD = '-PAD-'\n",
    "UNK = '-UNK-'\n",
    "word2int = {word: i + 2 for i, word in enumerate(sorted(wordset))}\n",
    "word2int[PAD] = 0  # special token for padding\n",
    "word2int[UNK] = 1  # special token for unknown words\n",
    " \n",
    "label2int = {label: i for i, label in enumerate(sorted(labelset))}\n",
    "# inverted index to translate it back\n",
    "int2label = {i:label for label, i in label2int.items()}\n",
    "\n",
    "\n",
    "def convert2ints(instances):\n",
    "    \"\"\"\n",
    "    function to apply the mapping to all words\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for words in instances:\n",
    "        # replace words with int, 1 for unknown words\n",
    "        word_ints = [word2int.get(word, 1) for word in words]\n",
    "        result.append(word_ints)\n",
    "    return result\n",
    "                          \n",
    "train_instances_int = convert2ints(train_instances)\n",
    "train_labels_int = [label2int[label] for label in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = test_data[input_column].apply(str).apply(str.split)\n",
    "test_labels = test_data[target]\n",
    "\n",
    "test_instances_int = convert2ints(test_instances)\n",
    "test_labels_int = [label2int[label] for label in test_labels]\n",
    "\n",
    "# convert dev data\n",
    "# val_instances = valid_data[input_column].apply(str).apply(str.split)\n",
    "# val_labels = valid_data[target]\n",
    "\n",
    "# val_instances_int = convert2ints(val_instances)\n",
    "# val_labels_int = [label2int[label] for label in val_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels_1hot = to_categorical(train_labels_int, len(label2int))\n",
    "test_labels_1hot = to_categorical(test_labels_int, len(label2int))\n",
    "# val_labels_1hot = to_categorical(val_labels_int, len(label2int))\n",
    "\n",
    "train_labels_1hot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "['kansas', 'kdhe', 'report', 'new', 'covid', 'cluster', 'thanksgive', 'variant', 'surge', 'kansas', 'say', 'unvaccinated', 'staff', 'member', 'blame', 'uptick', 'outbreak', 'nursing', 'home'] 19\n",
      "[2834 2842 4483 3481 1141  910 5286 5704 5157 2834 4665 5608 4997 3204\n",
      "  567 5627 3731 3608 2417    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0] 88\n"
     ]
    }
   ],
   "source": [
    "# compute 95th percentile of training sentence lengths\n",
    "L = sorted(map(len, train_instances))\n",
    "MAX_LENGTH = L[int(len(L)*0.95)]\n",
    "print(MAX_LENGTH)\n",
    "\n",
    "# apply padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_instances_int = pad_sequences(train_instances_int, padding='post', maxlen=MAX_LENGTH)\n",
    "test_instances_int = pad_sequences(test_instances_int, padding='post', maxlen=MAX_LENGTH)\n",
    "# val_instances_int = pad_sequences(val_instances_int, padding='post', maxlen=MAX_LENGTH)\n",
    "\n",
    "print(train_instances[0], len(train_instances[0]))\n",
    "print(train_instances_int[0], len(train_instances_int[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_instances_int)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_instances_int, label=train_labels_int)\n",
    "# dval = xgb.DMatrix(val_instances_int, label=val_labels_int)\n",
    "dtest = xgb.DMatrix(test_instances_int, label=test_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 8, 'eta': 1, 'objective': 'multi:softmax', 'num_class': 3, 'eval_metric': ['auc', 'ams@0'], 'nthread': 4, 'silent': 1}\n",
    "\n",
    "# evallist = [(dval, 'eval'), (dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:42:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:42:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:42:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:42:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:42:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_round = 500\n",
    "seed = 42\n",
    "cv_results = xgb.cv(\n",
    "    param, \n",
    "    dtrain, \n",
    "    num_boost_round=num_round,\n",
    "    seed=seed, \n",
    "    nfold=5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>train-ams@0-mean</th>\n",
       "      <th>train-ams@0-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "      <th>test-ams@0-mean</th>\n",
       "      <th>test-ams@0-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.900915</td>\n",
       "      <td>1.336258e-02</td>\n",
       "      <td>34.949895</td>\n",
       "      <td>0.374220</td>\n",
       "      <td>0.594228</td>\n",
       "      <td>0.029374</td>\n",
       "      <td>17.072891</td>\n",
       "      <td>0.740816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.961707</td>\n",
       "      <td>7.463874e-03</td>\n",
       "      <td>34.929276</td>\n",
       "      <td>0.379089</td>\n",
       "      <td>0.597834</td>\n",
       "      <td>0.011136</td>\n",
       "      <td>17.010711</td>\n",
       "      <td>0.816465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.984376</td>\n",
       "      <td>5.136256e-03</td>\n",
       "      <td>34.975444</td>\n",
       "      <td>0.377226</td>\n",
       "      <td>0.598530</td>\n",
       "      <td>0.018696</td>\n",
       "      <td>16.990067</td>\n",
       "      <td>0.723462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.993385</td>\n",
       "      <td>3.841671e-03</td>\n",
       "      <td>34.955855</td>\n",
       "      <td>0.379613</td>\n",
       "      <td>0.606092</td>\n",
       "      <td>0.017228</td>\n",
       "      <td>17.028570</td>\n",
       "      <td>0.724936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998507</td>\n",
       "      <td>5.366632e-04</td>\n",
       "      <td>34.942075</td>\n",
       "      <td>0.402223</td>\n",
       "      <td>0.607949</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>17.001048</td>\n",
       "      <td>0.718285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>8.469211e-07</td>\n",
       "      <td>34.941909</td>\n",
       "      <td>0.380199</td>\n",
       "      <td>0.630607</td>\n",
       "      <td>0.013507</td>\n",
       "      <td>17.006570</td>\n",
       "      <td>0.796489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>8.469211e-07</td>\n",
       "      <td>34.941909</td>\n",
       "      <td>0.380199</td>\n",
       "      <td>0.630524</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>17.006570</td>\n",
       "      <td>0.796489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>8.469211e-07</td>\n",
       "      <td>34.941909</td>\n",
       "      <td>0.380199</td>\n",
       "      <td>0.630531</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>17.006570</td>\n",
       "      <td>0.796489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>8.469211e-07</td>\n",
       "      <td>34.941909</td>\n",
       "      <td>0.380199</td>\n",
       "      <td>0.630620</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>17.006570</td>\n",
       "      <td>0.796489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>8.469211e-07</td>\n",
       "      <td>34.941909</td>\n",
       "      <td>0.380199</td>\n",
       "      <td>0.630760</td>\n",
       "      <td>0.013472</td>\n",
       "      <td>17.006570</td>\n",
       "      <td>0.796489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-auc-mean  train-auc-std  train-ams@0-mean  train-ams@0-std  \\\n",
       "0          0.900915   1.336258e-02         34.949895         0.374220   \n",
       "1          0.961707   7.463874e-03         34.929276         0.379089   \n",
       "2          0.984376   5.136256e-03         34.975444         0.377226   \n",
       "3          0.993385   3.841671e-03         34.955855         0.379613   \n",
       "4          0.998507   5.366632e-04         34.942075         0.402223   \n",
       "..              ...            ...               ...              ...   \n",
       "495        0.999999   8.469211e-07         34.941909         0.380199   \n",
       "496        0.999999   8.469211e-07         34.941909         0.380199   \n",
       "497        0.999999   8.469211e-07         34.941909         0.380199   \n",
       "498        0.999999   8.469211e-07         34.941909         0.380199   \n",
       "499        0.999999   8.469211e-07         34.941909         0.380199   \n",
       "\n",
       "     test-auc-mean  test-auc-std  test-ams@0-mean  test-ams@0-std  \n",
       "0         0.594228      0.029374        17.072891        0.740816  \n",
       "1         0.597834      0.011136        17.010711        0.816465  \n",
       "2         0.598530      0.018696        16.990067        0.723462  \n",
       "3         0.606092      0.017228        17.028570        0.724936  \n",
       "4         0.607949      0.016047        17.001048        0.718285  \n",
       "..             ...           ...              ...             ...  \n",
       "495       0.630607      0.013507        17.006570        0.796489  \n",
       "496       0.630524      0.013545        17.006570        0.796489  \n",
       "497       0.630531      0.013442        17.006570        0.796489  \n",
       "498       0.630620      0.013500        17.006570        0.796489  \n",
       "499       0.630760      0.013472        17.006570        0.796489  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup completed, training now\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             n_jobs=10,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.7, 1],\n",
       "                         'learning_rate': [0.01, 0.05, 0.1],\n",
       "                         'max_depth': [2, 3, 4, 5, 6, 7],\n",
       "                         'n_estimators': [100, 500, 1000], 'num_class': [3],\n",
       "                         'objective': ['multi:softprob']},\n",
       "             scoring='roc_auc_ovo', verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = { 'num_class': [3], \n",
    "        'max_depth' : [2, 3, 4, 5, 6, 7],\n",
    "        'learning_rate' : [0.01, 0.05, 0.1],\n",
    "        'n_estimators' : [100, 500, 1000],\n",
    "        'objective': ['multi:softprob'],\n",
    "        'colsample_bytree': [0.5, 0.7, 1]\n",
    "}\n",
    "\n",
    "xgbc = xgb.XGBClassifier(seed = 42)\n",
    "\n",
    "clf = GridSearchCV(estimator = xgbc,\n",
    "                param_grid = params,\n",
    "                scoring='roc_auc_ovo',\n",
    "                verbose = 1,\n",
    "                n_jobs = 10\n",
    "            \n",
    ")\n",
    "\n",
    "print('Setup completed, training now')\n",
    "\n",
    "clf.fit(train_instances_int, train_labels_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgbCVGridSearchC2.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(clf, 'xgbCVGridSearchC2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgbBest_CVC2.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = clf.best_estimator_\n",
    "\n",
    "dump(model, 'xgbBest_CVC2.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_class</th>\n",
       "      <th>param_objective</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4.659577</td>\n",
       "      <td>0.050357</td>\n",
       "      <td>0.020354</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'learning_rate': 0.1...</td>\n",
       "      <td>0.680106</td>\n",
       "      <td>0.661385</td>\n",
       "      <td>0.671104</td>\n",
       "      <td>0.67335</td>\n",
       "      <td>0.713803</td>\n",
       "      <td>0.679949</td>\n",
       "      <td>0.017958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "48       4.659577      0.050357         0.020354        0.008239   \n",
       "\n",
       "   param_colsample_bytree param_learning_rate param_max_depth  \\\n",
       "48                    0.5                 0.1               6   \n",
       "\n",
       "   param_n_estimators param_num_class param_objective  \\\n",
       "48                100               3  multi:softprob   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "48  {'colsample_bytree': 0.5, 'learning_rate': 0.1...           0.680106   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "48           0.661385           0.671104            0.67335   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "48           0.713803         0.679949        0.017958                1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['mean_test_score'] == df1['mean_test_score'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gridsearch = load('xgbCVGridSearch.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgboost.sklearn.XGBClassifier"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 1000, 'num_class': 3, 'objective': 'multi:softprob'}\n",
      "Highest AUC:  0.9309728292375551\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", Gridsearch.best_params_)\n",
    "print(\"Highest AUC: \", (Gridsearch.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(Gridesearch.cv_results_)\n",
    "# df1.to_csv('xgboost_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_class</th>\n",
       "      <th>param_objective</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>80.091854</td>\n",
       "      <td>8.578351</td>\n",
       "      <td>0.422838</td>\n",
       "      <td>0.032511</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'learning_rate': 0.1...</td>\n",
       "      <td>0.928852</td>\n",
       "      <td>0.929915</td>\n",
       "      <td>0.932881</td>\n",
       "      <td>0.929763</td>\n",
       "      <td>0.933452</td>\n",
       "      <td>0.930973</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>61.540091</td>\n",
       "      <td>6.199461</td>\n",
       "      <td>0.324311</td>\n",
       "      <td>0.029329</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'learning_rate': 0.1...</td>\n",
       "      <td>0.927215</td>\n",
       "      <td>0.928086</td>\n",
       "      <td>0.931972</td>\n",
       "      <td>0.927805</td>\n",
       "      <td>0.931833</td>\n",
       "      <td>0.929382</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>84.471425</td>\n",
       "      <td>9.330232</td>\n",
       "      <td>0.453256</td>\n",
       "      <td>0.045889</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'learning_rate': 0.0...</td>\n",
       "      <td>0.925553</td>\n",
       "      <td>0.927085</td>\n",
       "      <td>0.930634</td>\n",
       "      <td>0.926786</td>\n",
       "      <td>0.930606</td>\n",
       "      <td>0.928133</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>92.961855</td>\n",
       "      <td>7.584533</td>\n",
       "      <td>0.471483</td>\n",
       "      <td>0.070459</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'learning_rate': 0.1...</td>\n",
       "      <td>0.926387</td>\n",
       "      <td>0.926844</td>\n",
       "      <td>0.930113</td>\n",
       "      <td>0.926399</td>\n",
       "      <td>0.930192</td>\n",
       "      <td>0.927987</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>45.372425</td>\n",
       "      <td>1.339221</td>\n",
       "      <td>0.232754</td>\n",
       "      <td>0.016557</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'learning_rate': 0.1...</td>\n",
       "      <td>0.925062</td>\n",
       "      <td>0.926473</td>\n",
       "      <td>0.929667</td>\n",
       "      <td>0.926238</td>\n",
       "      <td>0.930366</td>\n",
       "      <td>0.927561</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "44      80.091854      8.578351         0.422838        0.032511   \n",
       "41      61.540091      6.199461         0.324311        0.029329   \n",
       "29      84.471425      9.330232         0.453256        0.045889   \n",
       "89      92.961855      7.584533         0.471483        0.070459   \n",
       "43      45.372425      1.339221         0.232754        0.016557   \n",
       "\n",
       "   param_colsample_bytree param_learning_rate param_max_depth  \\\n",
       "44                    0.5                 0.1              10   \n",
       "41                    0.5                 0.1               8   \n",
       "29                    0.5                0.05              10   \n",
       "89                    0.7                 0.1              10   \n",
       "43                    0.5                 0.1              10   \n",
       "\n",
       "   param_n_estimators param_num_class param_objective  \\\n",
       "44               1000               3  multi:softprob   \n",
       "41               1000               3  multi:softprob   \n",
       "29               1000               3  multi:softprob   \n",
       "89               1000               3  multi:softprob   \n",
       "43                500               3  multi:softprob   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "44  {'colsample_bytree': 0.5, 'learning_rate': 0.1...           0.928852   \n",
       "41  {'colsample_bytree': 0.5, 'learning_rate': 0.1...           0.927215   \n",
       "29  {'colsample_bytree': 0.5, 'learning_rate': 0.0...           0.925553   \n",
       "89  {'colsample_bytree': 0.7, 'learning_rate': 0.1...           0.926387   \n",
       "43  {'colsample_bytree': 0.5, 'learning_rate': 0.1...           0.925062   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "44           0.929915           0.932881           0.929763   \n",
       "41           0.928086           0.931972           0.927805   \n",
       "29           0.927085           0.930634           0.926786   \n",
       "89           0.926844           0.930113           0.926399   \n",
       "43           0.926473           0.929667           0.926238   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "44           0.933452         0.930973        0.001837                1  \n",
       "41           0.931833         0.929382        0.002077                2  \n",
       "29           0.930606         0.928133        0.002095                3  \n",
       "89           0.930192         0.927987        0.001776                4  \n",
       "43           0.930366         0.927561        0.002073                5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sort_values(['rank_test_score']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('xgboost_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = model.predict_proba(test_instances_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.predict(test_instances_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba.tofile('../../../Files/models/xgb_proba.txt', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tofile('../../../Files/models/xgb_test.txt', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('reddit_env_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c5bfe69c2b2d435baea75ee1a7865fc7666bb526179204de658e4f2811cb086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
