{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import sklearn as skl \n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'label'\n",
    "input_column = 'cleanTitle'\n",
    "\n",
    "train_data = pd.read_pickle('../../../Files/Submissions/train/train_split_submission.pickle') \n",
    "valid_data = pd.read_pickle('../../../Files/Submissions/train/val_split_submission.pickle')\n",
    "test_data = pd.read_pickle('../../../Files/Submissions/train/test_split_submission.pickle')\n",
    "\n",
    "train_data = train_data[[target, input_column]]\n",
    "valid_data = valid_data[[target, input_column]]\n",
    "test_data = test_data[[target, input_column]]\n",
    "\n",
    "data = pd.concat([train_data, valid_data, test_data])\n",
    "\n",
    "\n",
    "train_instances = train_data[input_column].apply(str).apply(str.split)\n",
    "train_labels = train_data[target]\n",
    "\n",
    "# collect known word tokens and tags\n",
    "wordset, labelset = set(), set()\n",
    "\n",
    "# collect tags from all data, to prevent unseen labels\n",
    "labelset.update(set(data[target]))\n",
    "\n",
    "# get the vocabulary\n",
    "for words in train_instances:\n",
    "    wordset.update(set(words))\n",
    "\n",
    "# map words and tags into ints\n",
    "PAD = '-PAD-'\n",
    "UNK = '-UNK-'\n",
    "word2int = {word: i + 2 for i, word in enumerate(sorted(wordset))}\n",
    "word2int[PAD] = 0  # special token for padding\n",
    "word2int[UNK] = 1  # special token for unknown words\n",
    " \n",
    "label2int = {label: i for i, label in enumerate(sorted(labelset))}\n",
    "# inverted index to translate it back\n",
    "int2label = {i:label for label, i in label2int.items()}\n",
    "\n",
    "\n",
    "def convert2ints(instances):\n",
    "    \"\"\"\n",
    "    function to apply the mapping to all words\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for words in instances:\n",
    "        # replace words with int, 1 for unknown words\n",
    "        word_ints = [word2int.get(word, 1) for word in words]\n",
    "        result.append(word_ints)\n",
    "    return result\n",
    "                          \n",
    "train_instances_int = convert2ints(train_instances)\n",
    "train_labels_int = [label2int[label] for label in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = test_data[input_column].apply(str).apply(str.split)\n",
    "test_labels = test_data[target]\n",
    "\n",
    "test_instances_int = convert2ints(test_instances)\n",
    "test_labels_int = [label2int[label] for label in test_labels]\n",
    "\n",
    "# convert dev data\n",
    "val_instances = valid_data[input_column].apply(str).apply(str.split)\n",
    "val_labels = valid_data[target]\n",
    "\n",
    "val_instances_int = convert2ints(val_instances)\n",
    "val_labels_int = [label2int[label] for label in val_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels_1hot = to_categorical(train_labels_int, len(label2int))\n",
    "test_labels_1hot = to_categorical(test_labels_int, len(label2int))\n",
    "val_labels_1hot = to_categorical(val_labels_int, len(label2int))\n",
    "\n",
    "train_labels_1hot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['shill', 'organization'] 2\n",
      "[22655 17709     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0] 15\n"
     ]
    }
   ],
   "source": [
    "# compute 95th percentile of training sentence lengths\n",
    "L = sorted(map(len, train_instances))\n",
    "MAX_LENGTH = L[int(len(L)*0.95)]\n",
    "print(MAX_LENGTH)\n",
    "\n",
    "# apply padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_instances_int = pad_sequences(train_instances_int, padding='post', maxlen=MAX_LENGTH)\n",
    "test_instances_int = pad_sequences(test_instances_int, padding='post', maxlen=MAX_LENGTH)\n",
    "val_instances_int = pad_sequences(val_instances_int, padding='post', maxlen=MAX_LENGTH)\n",
    "\n",
    "print(train_instances[0], len(train_instances[0]))\n",
    "print(train_instances_int[0], len(train_instances_int[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jakobschlierf/Desktop/Master/Thesis/Github/classifier/explainable/xgboost.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jakobschlierf/Desktop/Master/Thesis/Github/classifier/explainable/xgboost.ipynb#ch0000014?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(train_instances_int), train_labels_int\u001b[39m.\u001b[39;49msize)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "print(len(train_instances_int), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_instances_int, label=train_labels_int)\n",
    "dval = xgb.DMatrix(val_instances_int, label=val_labels_int)\n",
    "dtest = xgb.DMatrix(test_instances_int, label=test_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 8, 'eta': 1, 'objective': 'multi:softmax', 'num_class': 3, 'eval_metric': ['auc', 'ams@0'], 'nthread': 4, 'silent': 1}\n",
    "\n",
    "evallist = [(dval, 'eval'), (dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 500\n",
    "seed = 42\n",
    "cv_results = xgb.cv(\n",
    "    param, \n",
    "    dtrain, \n",
    "    num_boost_round=num_round,\n",
    "    seed=seed, \n",
    "    nfold=5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>train-ams@0-mean</th>\n",
       "      <th>train-ams@0-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "      <th>test-ams@0-mean</th>\n",
       "      <th>test-ams@0-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.629418</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>218.150577</td>\n",
       "      <td>0.747202</td>\n",
       "      <td>0.628457</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>109.073407</td>\n",
       "      <td>1.310451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.659238</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>218.328955</td>\n",
       "      <td>0.672002</td>\n",
       "      <td>0.657398</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>109.110620</td>\n",
       "      <td>1.329719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.674442</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>218.331677</td>\n",
       "      <td>0.670202</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>109.132208</td>\n",
       "      <td>1.338270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.686991</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>218.334494</td>\n",
       "      <td>0.672477</td>\n",
       "      <td>0.684855</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>109.122501</td>\n",
       "      <td>1.336336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.699018</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>218.338000</td>\n",
       "      <td>0.671468</td>\n",
       "      <td>0.696113</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>109.107233</td>\n",
       "      <td>1.325778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.942751</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>218.333984</td>\n",
       "      <td>0.674818</td>\n",
       "      <td>0.909610</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>109.118729</td>\n",
       "      <td>1.331167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.942808</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>218.333984</td>\n",
       "      <td>0.674818</td>\n",
       "      <td>0.909649</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>109.118729</td>\n",
       "      <td>1.331167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.942894</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>218.332883</td>\n",
       "      <td>0.673912</td>\n",
       "      <td>0.909704</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>109.118729</td>\n",
       "      <td>1.331167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.942959</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>218.332883</td>\n",
       "      <td>0.673912</td>\n",
       "      <td>0.909735</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>109.117049</td>\n",
       "      <td>1.329781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.943034</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>218.332513</td>\n",
       "      <td>0.674247</td>\n",
       "      <td>0.909718</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>109.117049</td>\n",
       "      <td>1.329781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-auc-mean  train-auc-std  train-ams@0-mean  train-ams@0-std  \\\n",
       "0          0.629418       0.001968        218.150577         0.747202   \n",
       "1          0.659238       0.001865        218.328955         0.672002   \n",
       "2          0.674442       0.001330        218.331677         0.670202   \n",
       "3          0.686991       0.002981        218.334494         0.672477   \n",
       "4          0.699018       0.001159        218.338000         0.671468   \n",
       "..              ...            ...               ...              ...   \n",
       "495        0.942751       0.000362        218.333984         0.674818   \n",
       "496        0.942808       0.000386        218.333984         0.674818   \n",
       "497        0.942894       0.000384        218.332883         0.673912   \n",
       "498        0.942959       0.000385        218.332883         0.673912   \n",
       "499        0.943034       0.000382        218.332513         0.674247   \n",
       "\n",
       "     test-auc-mean  test-auc-std  test-ams@0-mean  test-ams@0-std  \n",
       "0         0.628457      0.005338       109.073407        1.310451  \n",
       "1         0.657398      0.004045       109.110620        1.329719  \n",
       "2         0.673267      0.004630       109.132208        1.338270  \n",
       "3         0.684855      0.005718       109.122501        1.336336  \n",
       "4         0.696113      0.004645       109.107233        1.325778  \n",
       "..             ...           ...              ...             ...  \n",
       "495       0.909610      0.001936       109.118729        1.331167  \n",
       "496       0.909649      0.002002       109.118729        1.331167  \n",
       "497       0.909704      0.002010       109.118729        1.331167  \n",
       "498       0.909735      0.002010       109.117049        1.329781  \n",
       "499       0.909718      0.001970       109.117049        1.329781  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('reddit_env_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c5bfe69c2b2d435baea75ee1a7865fc7666bb526179204de658e4f2811cb086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
